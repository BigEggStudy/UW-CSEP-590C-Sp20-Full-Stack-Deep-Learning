# Assignment 1: Deep Learning Fundamentals

## Q1 Activation Function
What is the purpose of the activation function in a multi-layer perceptron?

## Q2 Representative Power
How many hidden layers in a multi-layer perceptron are needed to represent any function? Briefly explain your answer.

## Q3 Sigmoid vs ReLU
List two reasons to prefer the ReLU activation function over the sigmoid activation function.

![Sigmoid vs ReLU](https://s3-us-west-2.amazonaws.com/gradescope-static-assets/fsdl/sigmoid_vs_relu.png)

## Q4 Free-form
What do you hope to get out of this class? What are some problems that you hope to apply deep learning to?
